{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Deeplake to construct a dataset as fast as possible (write heavy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import deeplake as dl\n",
    "import numpy as np\n",
    "from termcolor import colored\n",
    "import psutil\n",
    "import shutil\n",
    "\n",
    "# construct dataset \n",
    "# RESULTS_DATASET_PATH = '/mnt/weka/deeplake/deeplake-ds-200k'\n",
    "# RESULTS_DATASET_PATH = '/dev/kas_temp/deeplake-ds-25k'\n",
    "RESULTS_DATASET_PATH = '/fsx/kas_temp/deeplake-ds-200k'\n",
    "\n",
    "shutil.rmtree(RESULTS_DATASET_PATH, ) if os.path.exists(RESULTS_DATASET_PATH) else None\n",
    "os.makedirs(RESULTS_DATASET_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[7m\u001b[36m👉 Creating output database at /fsx/kas_temp/deeplake-ds-200k\u001b[0m\n",
      "/fsx/kas_temp/deeplake-ds-200k loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "print(colored(f\"👉 Creating output database at {RESULTS_DATASET_PATH}\", \"cyan\", attrs=[\"reverse\", \"bold\"]))\n",
    "output_ds = dl.empty(RESULTS_DATASET_PATH, overwrite=True)\n",
    "with output_ds:\n",
    "  # tf_bfloat16 = _pywrap_bfloat16.TF_bfloat16_type() # couldn't get this working weird imports.\n",
    "  output_ds.create_tensor(\"context_vector\", htype=\"generic\", dtype=np.float32, sample_compression=None) #) \"lz4\")\n",
    "  # output_ds.create_tensor(\"label\", htype=\"text\", dtype=str, sample_compression=None)\n",
    "  output_ds.flush()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test read performance: Use the Deeplake Dataset as a Pytorch Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/fsx/kas_temp/deeplake-ds-200k loaded successfully.\n",
      "\n",
      " \r"
     ]
    }
   ],
   "source": [
    "RESULTS_DATASET_PATH = '/fsx/kas_temp/deeplake-ds-200k'\n",
    "os.remove(os.path.join(RESULTS_DATASET_PATH, 'dataset_lock.lock')) if os.path.exists(os.path.join(RESULTS_DATASET_PATH, 'dataset_lock.lock')) else None\n",
    "\n",
    "fifty_gb = int(20 * 1e9)\n",
    "output_ds = dl.load(RESULTS_DATASET_PATH, read_only=False, memory_cache_size=fifty_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m      2\u001b[0m dataloader\u001b[39m=\u001b[39m output_ds\u001b[39m.\u001b[39mpytorch(batch_size \u001b[39m=\u001b[39m \u001b[39m16\u001b[39m, num_workers \u001b[39m=\u001b[39m \u001b[39m2\u001b[39m, \n\u001b[1;32m      3\u001b[0m     \u001b[39m# transform = transform, \u001b[39;00m\n\u001b[1;32m      4\u001b[0m     tensors \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mcontext_vector\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m      5\u001b[0m     shuffle \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "dataloader= output_ds.pytorch(batch_size = 16, num_workers = 2, \n",
    "    # transform = transform, \n",
    "    tensors = ['context_vector'],\n",
    "    shuffle = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Using cached torch-2.0.0-cp38-cp38-manylinux1_x86_64.whl (619.9 MB)\n",
      "Collecting nvidia-cuda-cupti-cu11==11.7.101\n",
      "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m43.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96\n",
      "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m588.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /home/ec2-user/utils/miniconda3/envs/async/lib/python3.8/site-packages (from torch) (4.5.0)\n",
      "Collecting nvidia-cusolver-cu11==11.4.0.1\n",
      "  Using cached nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
      "Collecting nvidia-cublas-cu11==11.10.3.66\n",
      "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.7.99\n",
      "  Using cached nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
      "Collecting nvidia-nccl-cu11==2.14.3\n",
      "  Using cached nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
      "Collecting nvidia-cuda-runtime-cu11==11.7.99\n",
      "  Using cached nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
      "Collecting triton==2.0.0\n",
      "  Using cached triton-2.0.0-1-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.2 MB)\n",
      "Collecting sympy\n",
      "  Using cached sympy-1.11.1-py3-none-any.whl (6.5 MB)\n",
      "Collecting nvidia-cusparse-cu11==11.7.4.91\n",
      "  Using cached nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
      "\u001b[31mERROR: Could not install packages due to an OSError: [Errno 28] No space left on device\n",
      "\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in dataloader:\n",
    "    print(data)    \n",
    "    break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restart notebook here, close connection to output_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import deeplake as dl\n",
    "import numpy as np\n",
    "from termcolor import colored\n",
    "import psutil\n",
    "\n",
    "# construct dataset \n",
    "RESULTS_DATASET_PATH = '/mnt/weka/deeplake/deeplake-ds-3'\n",
    "os.makedirs(RESULTS_DATASET_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populate dataset, in parallel, using all but 1 CPU core. \n",
    "@dl.compute\n",
    "def populate_ds_with_zeros(sample_in, sample_out, min_val, max_val, arr_shape, dtype=np.float32):\n",
    "  # caption = sample_in.caption.numpy()\n",
    "  sample_out.context_vector.append( np.array(np.random.uniform(min_val,max_val,arr_shape), dtype=dtype) )\n",
    "  return sample_out\n",
    "\n",
    "# experiment settings\n",
    "min = np.finfo(np.float32).min\n",
    "max = np.finfo(np.float32).max\n",
    "arr_shape = (1024,1024)\n",
    "dtype = np.float32\n",
    "dataset_size = [None] * 1_000\n",
    "\n",
    "output_ds = dl.load(RESULTS_DATASET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "populate_ds_with_zeros(min_val=min, max_val=max, arr_shape=arr_shape, dtype=dtype).eval(dataset_size, output_ds, scheduler=\"ray\", num_workers=psutil.cpu_count()-1, skip_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_ds = dl.load(RESULTS_DATASET_PATH)\n",
    "output_ds.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
